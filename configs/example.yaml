# configs/example.yaml

### This is an example configuration file for the hyperparameters of our GNN competition. ###

# Dataset & tasks
dataset: MUTAG            # KarateClub | MUTAG   
task: graph               # graph | node 
device: cpu               # cuda | mps | cpu | auto
random_seed: 42 

# Model architecture
layers: 3                 # Number of GNN layers
hidden_dim: 64            # Size of hidden layers embeddings
dropout: 0.5              # Dropout rate for regularization 
layer_type: GCN           # GCN | GAT | GraphSAGE | GIN
aggregator: mean          # mean | sum | max 
update_fn: MLP            # MLP | Attention | BLSTM  
global_pool: sum          # mean | add | max (for graph tasks)

# Optimization
optimizer: 
  type: Adam              # Adam | SGD 
  lr: 0.001               # Learning rate 
  weight_decay: 0.0001    # Decay rate for L2 regularization

# Training
batch_size: 32
epochs: 100
